{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926096e8-23ac-43b3-a99e-e33fa9da3cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REGEX\n",
    "# Email validator\n",
    "import re\n",
    "email = input('Enter email : ')\n",
    "print(re.findall(\"[^a-z,' ']\",email))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24deee0a-1588-4825-9cff-f1d82c987536",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'maharshi@gmail.com'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8961f39e-fe63-488d-8223-325c825a70d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REGEX\n",
    "# Email validator\n",
    "import re\n",
    "email = input('Enter email : ')\n",
    "print(re.findall(\"[^a-z,' ']\",email))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6852242-e59e-43be-9f52-b5b620e5a792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter email :  The Maharshi\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['T', 'M']\n"
     ]
    }
   ],
   "source": [
    "# REGEX\n",
    "# Email validator\n",
    "import re\n",
    "email = input('Enter email : ')\n",
    "print(re.findall(\"[^a-z,' ']\",email))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75fcc375-9983-4e1e-ac08-c8f6117b6af8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.', '.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\.'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\.'\n",
      "/tmp/ipykernel_3424/574486441.py:2: SyntaxWarning: invalid escape sequence '\\.'\n",
      "  print(re.findall('\\.',txt))\n"
     ]
    }
   ],
   "source": [
    "txt = 'that will e .59 dollars.'\n",
    "print(re.findall('\\.',txt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e7bdb1b-f534-4e16-9e16-6ccd2298970b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Namaste']\n"
     ]
    }
   ],
   "source": [
    "txt = 'Namaste World'\n",
    "print(re.findall('^Namaste',txt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20bd2ca6-bed0-4dc4-a833-8c31e515f9e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maharshibhatt043@hotmail.com\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "email = 'maharshibhatt043@hotmail.com'\n",
    "pattern = r'\\b([a-z0-9]+)@([a-z]+).com\\b'\n",
    "match = re.match(pattern,email)\n",
    "print(match.group())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a41a014d-d876-42c1-8731-816f498eac69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your password:  mAharshi@05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Password is Strong.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def check_password_strength(password):\n",
    "    # Define the regular expression pattern\n",
    "    pattern = r'^(?=.*[a-z])(?=.*[A-Z])(?=.*\\d)(?=.*[@$!%*?&])[A-Za-z\\d@$!%*?&]{8,}$'\n",
    "    \n",
    "    # Match using re.fullmatch for complete match\n",
    "    if re.fullmatch(pattern, password):\n",
    "        print(\"‚úÖ Password is Strong.\")\n",
    "    else:\n",
    "        print(\"‚ùå Password is Weak.\")\n",
    "        print(\"üîí Your password must have:\")\n",
    "        print(\" - At least 1 uppercase letter\")\n",
    "        print(\" - At least 1 lowercase letter\")\n",
    "        print(\" - At least 1 digit\")\n",
    "        print(\" - At least 1 special character (@$!%*?&)\")\n",
    "        print(\" - Minimum 8 characters in length\")\n",
    "\n",
    "# Example usage\n",
    "password = input(\"Enter your password: \")\n",
    "check_password_strength(password)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a08a6074-36ea-4d2b-af0f-4b83a6a0541b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "www.data.gov\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:3: SyntaxWarning: invalid escape sequence '\\.'\n",
      "<>:3: SyntaxWarning: invalid escape sequence '\\.'\n",
      "/tmp/ipykernel_599/2448726468.py:3: SyntaxWarning: invalid escape sequence '\\.'\n",
      "  pattern = 'www\\.[a-zA-Z0-9]+\\.(com|in|gov|org|net)'\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "urltxt = 'Im on www.data.gov site so now we can contact'\n",
    "pattern = 'www\\.[a-zA-Z0-9]+\\.(com|in|gov|org|net)'\n",
    "res = re.search(pattern,urltxt)\n",
    "print(res.group())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d7dedd6-8abb-44c8-b008-fe3ae2eab341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192.168.0.1\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "pattern = r'^((25[0-4]|2[0-4]\\d|1\\d{2}|[0-9]?\\d)\\.){3}(25[0-4]|2[0-4]\\d|1\\d{2}|[0-9]?\\d)$'\n",
    "ip = '192.168.0.1'\n",
    "res = re.match(pattern,ip)\n",
    "print(res.group())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a46e86f4-12a2-4e25-b032-6f9937df4631",
   "metadata": {},
   "outputs": [],
   "source": [
    "#HTML tag extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ddd2b79-b5fe-419d-a77c-a63d0a5dd8c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üõ† Extracted HTML Tags:\n",
      "<html>\n",
      "<head>\n",
      "<title>\n",
      "</title>\n",
      "</head>\n",
      "<body>\n",
      "<h1>\n",
      "</h1>\n",
      "<p>\n",
      "<b>\n",
      "</b>\n",
      "</p>\n",
      "<img src=\"image.jpg\" alt=\"sample image\" />\n",
      "</body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def extract_html_tags(html_text):\n",
    "    # Regex to match any HTML tag: <tag> or </tag> or self-closing\n",
    "    pattern = r'</?[a-zA-Z][a-zA-Z0-9]*[^<>]*?>'\n",
    "    \n",
    "    # Find all matching tags\n",
    "    tags = re.findall(pattern, html_text)\n",
    "    return tags\n",
    "\n",
    "# Example HTML input\n",
    "html_doc = \"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<head><title>Sample Page</title></head>\n",
    "<body>\n",
    "    <h1>Hello, World!</h1>\n",
    "    <p>This is a <b>bold</b> paragraph.</p>\n",
    "    <img src=\"image.jpg\" alt=\"sample image\" />\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "# Extract tags\n",
    "html_tags = extract_html_tags(html_doc)\n",
    "\n",
    "# Print results\n",
    "print(\"üõ† Extracted HTML Tags:\")\n",
    "for tag in html_tags:\n",
    "    print(tag)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0546ac51-7537-4214-8d8d-725aedc17fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìå Python-related Job Titles:\n",
      "Senior Python Developer\n",
      "\n",
      "üìå All Job Titles, Locations, and Companies:\n",
      "Title: Senior Python Developer | Location: San Francisco | Company: OpenAI\n",
      "\n",
      "üìä DataFrame of Python Jobs:\n",
      "                     Title       Location Company\n",
      "0  Senior Python Developer  San Francisco  OpenAI\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Step 1: Read the HTML file\n",
    "with open('fakepython.html', 'r', encoding='utf-8') as file:\n",
    "    html = file.read()\n",
    "\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "# Step 2: Extract Python-related job titles\n",
    "print(\"üìå Python-related Job Titles:\")\n",
    "python_jobs = soup.find_all('h2', class_='title')\n",
    "\n",
    "for job in python_jobs:\n",
    "    if 'python' in job.text.lower():\n",
    "        print(job.text.strip())\n",
    "\n",
    "# Step 3: Extract all job titles, locations, and companies\n",
    "print(\"\\nüìå All Job Titles, Locations, and Companies:\")\n",
    "jobs = soup.find_all('div', class_='card-content')\n",
    "\n",
    "for job in jobs:\n",
    "    title = job.find('h2', class_='title').text.strip()\n",
    "    location = job.find('p', class_='location').text.strip()\n",
    "    company = job.find('h3', class_='company').text.strip()\n",
    "    print(f\"Title: {title} | Location: {location} | Company: {company}\")\n",
    "\n",
    "# Step 4: Create a DataFrame for Python-related jobs\n",
    "job_list = []\n",
    "\n",
    "for job in jobs:\n",
    "    title = job.find('h2', class_='title').text.strip()\n",
    "    if 'python' in title.lower():\n",
    "        location = job.find('p', class_='location').text.strip()\n",
    "        company = job.find('h3', class_='company').text.strip()\n",
    "        job_list.append({'Title': title, 'Location': location, 'Company': company})\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(job_list)\n",
    "\n",
    "print(\"\\nüìä DataFrame of Python Jobs:\")\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14e6cbb4-4b57-4e19-8032-c31ca70a45a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in /home/codespace/.local/lib/python3.12/site-packages (4.13.4)\n",
      "Requirement already satisfied: pandas in /home/codespace/.local/lib/python3.12/site-packages (2.3.1)\n",
      "Collecting lxml\n",
      "  Downloading lxml-6.0.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/codespace/.local/lib/python3.12/site-packages (from beautifulsoup4) (2.7)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /home/codespace/.local/lib/python3.12/site-packages (from beautifulsoup4) (4.14.1)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /home/codespace/.local/lib/python3.12/site-packages (from pandas) (2.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/codespace/.local/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/codespace/.local/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/codespace/.local/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/codespace/.local/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Downloading lxml-6.0.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (5.3 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: lxml\n",
      "Successfully installed lxml-6.0.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install beautifulsoup4 pandas lxml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6226703c-86d8-4f18-bb19-808a1204b243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìå Python-related Job Titles:\n",
      "Senior Python Developer\n",
      "Data Scientist (Python)\n",
      "Python Engineer\n",
      "\n",
      "üìå All Job Titles, Locations, and Companies:\n",
      "Title: Senior Python Developer | Location: San Francisco, CA | Company: OpenAI\n",
      "Title: JavaScript Engineer | Location: Mountain View, CA | Company: Google\n",
      "Title: Data Scientist (Python) | Location: Redmond, WA | Company: Microsoft\n",
      "Title: Frontend Developer | Location: Menlo Park, CA | Company: Meta\n",
      "Title: Python Engineer | Location: Los Gatos, CA | Company: Netflix\n",
      "\n",
      "üìä DataFrame of Python Jobs:\n",
      "                     Title           Location    Company\n",
      "0  Senior Python Developer  San Francisco, CA     OpenAI\n",
      "1  Data Scientist (Python)        Redmond, WA  Microsoft\n",
      "2          Python Engineer      Los Gatos, CA    Netflix\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Step 1: Read the HTML file\n",
    "with open('fakepython.html', 'r', encoding='utf-8') as file:\n",
    "    html = file.read()\n",
    "\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "# Step 2: Extract Python-related job titles\n",
    "print(\"üìå Python-related Job Titles:\")\n",
    "python_jobs = soup.find_all('h2', class_='title')\n",
    "\n",
    "for job in python_jobs:\n",
    "    if 'python' in job.text.lower():\n",
    "        print(job.text.strip())\n",
    "\n",
    "# Step 3: Extract all job titles, locations, and companies\n",
    "print(\"\\nüìå All Job Titles, Locations, and Companies:\")\n",
    "jobs = soup.find_all('div', class_='card-content')\n",
    "\n",
    "for job in jobs:\n",
    "    title = job.find('h2', class_='title').text.strip()\n",
    "    location = job.find('p', class_='location').text.strip()\n",
    "    company = job.find('h3', class_='company').text.strip()\n",
    "    print(f\"Title: {title} | Location: {location} | Company: {company}\")\n",
    "\n",
    "# Step 4: Create a DataFrame for Python-related jobs\n",
    "job_list = []\n",
    "\n",
    "for job in jobs:\n",
    "    title = job.find('h2', class_='title').text.strip()\n",
    "    if 'python' in title.lower():\n",
    "        location = job.find('p', class_='location').text.strip()\n",
    "        company = job.find('h3', class_='company').text.strip()\n",
    "        job_list.append({'Title': title, 'Location': location, 'Company': company})\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(job_list)\n",
    "\n",
    "print(\"\\nüìä DataFrame of Python Jobs:\")\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b970ec80-ae7f-41e8-830f-73d18a4b8719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html lang=\"en\">\n",
      "<head>\n",
      "    <meta charset=\"UTF-8\">\n",
      "    <title>Fake Python Job Board</title>\n",
      "</head>\n",
      "<body>\n",
      "    <div class=\"card-content\">\n",
      "        <h2 class=\"title\">Senior Python Developer</h2>\n",
      "        <h3 class=\"company\">OpenAI</h3>\n",
      "        <p class=\"location\">San Francisco, CA</p>\n",
      "    </div>\n",
      "    <div class=\"card-content\">\n",
      "        <h2 class=\"title\">JavaScript Engineer</h2>\n",
      "        <h3 class=\"company\">Google</h3>\n",
      "        <p class=\"location\">Mountain View, CA</p>\n",
      "    </div>\n",
      "    <div class=\"card-content\">\n",
      "        <h2 class=\"title\">Data Scientist (Python)</h2>\n",
      "        <h3 class=\"company\">Microsoft</h3>\n",
      "        <p class=\"location\">Redmond, WA</p>\n",
      "    </div>\n",
      "    <div class=\"card-content\">\n",
      "        <h2 class=\"title\">Frontend Developer</h2>\n",
      "        <h3 class=\"company\">Meta</h3>\n",
      "        <p class=\"location\">Menlo Park, CA</p>\n",
      "    </div>\n",
      "    <div class=\"card-content\">\n",
      "        <h2 class=\"title\">Python Engineer</h2>\n",
      "        <h3 class=\"company\">Netflix</h3>\n",
      "        <p class=\"location\">Los Gatos, CA</p>\n",
      "    </div>\n",
      "</body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Read html file\n",
    "with open('fakepython.html','r',encoding='utf-8') as file: \n",
    "    html = file.read()\n",
    "\n",
    "print(html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f71a5c6a-b3b5-4964-813c-e6893f47674c",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(html,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1fcb0c4e-6de8-4d3e-8144-5d29bce71a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Senior Python Developer\n",
      "Data Scientist (Python)\n",
      "Python Engineer\n"
     ]
    }
   ],
   "source": [
    "jobs = soup.find_all('h2', class_='title')\n",
    "\n",
    "for job in jobs : \n",
    "    if 'python' in job.text.lower() : \n",
    "        print(job.text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3785291b-9edc-4420-a6ee-1c51b6bc5644",
   "metadata": {},
   "outputs": [],
   "source": [
    "locations = soup.find_all('div', class_='location')\n",
    "for loc in locations : \n",
    "    print(loc.text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91e071f-8505-4d24-853e-d0750ac62935",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
